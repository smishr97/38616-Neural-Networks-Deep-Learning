{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smishr97/38616-Neural-Networks-Deep-Learning/blob/main/ShivamMishra_NN_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07253bf4-442f-4d7c-9339-3ae24519fdff",
      "metadata": {
        "id": "07253bf4-442f-4d7c-9339-3ae24519fdff"
      },
      "source": [
        "## 36-616: Neural Network and Deep Learning\n",
        "### Homework #1: Neural Network from ***Scratch***\n",
        "**Name: Shivam Mishra** <br>\n",
        "**AndrewID: shivammi**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd62743b-4a2c-4d52-bc14-913d7bc5023d",
      "metadata": {
        "id": "cd62743b-4a2c-4d52-bc14-913d7bc5023d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from typing import Optional, List, Tuple, Dict\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "plt.style.use('bmh')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bb94c62-8b92-47aa-9b05-ffc744513862",
      "metadata": {
        "id": "6bb94c62-8b92-47aa-9b05-ffc744513862"
      },
      "outputs": [],
      "source": [
        "# For CUDA based devices\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# ## For MacOS based devices\n",
        "# if torch.backends.mps.is_available():\n",
        "#     device = torch.device(\"mps\")\n",
        "# else:\n",
        "#     device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465651b4-fc66-4a23-9935-f4dd7629fbbb",
      "metadata": {
        "id": "465651b4-fc66-4a23-9935-f4dd7629fbbb"
      },
      "outputs": [],
      "source": [
        "class Transform(object):\n",
        "    \"\"\"\n",
        "    This is the base class. You do not need to change anything.\n",
        "    Read the comments in this class carefully.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        Initialize any parameters\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x should be passed as column vectors\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def backward(self, grad_wrt_out):\n",
        "        \"\"\"\n",
        "        Compute and save the gradients wrt the parameters for step()\n",
        "        Return grad_wrt_x which will be the grad_wrt_out for previous Transform\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"\n",
        "        Apply gradients to update the parameters\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def zerograd(self):\n",
        "        \"\"\"\n",
        "        This is used to Reset the gradients.\n",
        "        Usually called before backward()\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7845492-4795-4a4a-8c5c-197b38b5dc08",
      "metadata": {
        "id": "b7845492-4795-4a4a-8c5c-197b38b5dc08"
      },
      "outputs": [],
      "source": [
        "# Define a class named ReLU, which inherits from the Transform class\n",
        "class ReLU(Transform):\n",
        "    def __init__(self):\n",
        "        # Call the constructor of the parent class\n",
        "        super(ReLU, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the ReLU activation function.\n",
        "        \n",
        "        x: input tensor with shape (indim, batch_size)\n",
        "        output: output tensor with the same shape as x\n",
        "        \"\"\"\n",
        "        # Store the input tensor in an instance variable\n",
        "        self.x = x\n",
        "        # Apply the ReLU activation function to the input tensor and store the result in an instance variable\n",
        "        self.output = torch.max(x, torch.zeros_like(x))\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, grad_wrt_out):\n",
        "        \"\"\"\n",
        "        Backward pass of the ReLU activation function.\n",
        "        \n",
        "        grad_wrt_out: gradient of the loss function with respect to the output tensor\n",
        "                      with shape (outdim, batch_size)\n",
        "        \"\"\"\n",
        "        # Compute the gradient of the loss function with respect to the input tensor using the chain rule and the\n",
        "        # derivative of the ReLU activation function\n",
        "        return grad_wrt_out * (self.output > 0).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16e65362-c907-4758-9656-65b71f417b12",
      "metadata": {
        "id": "16e65362-c907-4758-9656-65b71f417b12"
      },
      "outputs": [],
      "source": [
        "# Define a class named LinearMap, which inherits from the Transform class\n",
        "class LinearMap(Transform):\n",
        "    def __init__(self, indim, outdim, lr=0.001):\n",
        "        \"\"\"\n",
        "        Constructor of the LinearMap class.\n",
        "\n",
        "        indim: input dimension\n",
        "        outdim: output dimension\n",
        "        lr: learning rate\n",
        "        \"\"\"\n",
        "        # Call the constructor of the parent class\n",
        "        super(LinearMap, self).__init__()\n",
        "        # Initialize the weight and bias tensors with random values\n",
        "        self.weights = 0.01 *torch.rand((outdim, indim), dtype=torch.float64, requires_grad=True, device=device)\n",
        "        self.bias = 0.01 * torch.rand((outdim, 1), dtype=torch.float64, requires_grad=True, device=device)\n",
        "        # Set the learning rate\n",
        "        self.lr = lr\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the linear transformation.\n",
        "\n",
        "        x: input tensor with shape (indim, batch_size)\n",
        "        output: output tensor with shape (outdim, batch_size)\n",
        "        \"\"\"\n",
        "        # Store the input tensor in an instance variable\n",
        "        self.input = x\n",
        "        # Apply the linear transformation to the input tensor and return the result\n",
        "        return torch.add(torch.matmul(self.weights, x), self.bias)\n",
        "\n",
        "\n",
        "    def backward(self, grad_wrt_out):\n",
        "        \"\"\"\n",
        "        Backward pass of the linear transformation.\n",
        "\n",
        "        grad_wrt_out: gradient of the loss function with respect to the output tensor\n",
        "                      with shape (outdim, batch_size)\n",
        "        grad_wrt_input: gradient of the loss function with respect to the input tensor\n",
        "                        with shape (indim, batch_size)\n",
        "        \"\"\"\n",
        "        # Compute the gradient of the loss function with respect to the weights and bias tensors using the chain rule\n",
        "        # and the gradients of the loss function with respect to the output tensor\n",
        "        grad_wrt_weights = torch.matmul(grad_wrt_out, self.input.t())\n",
        "        self.bias.grad = torch.sum(grad_wrt_out, dim=1, keepdim=True)\n",
        "        # Compute the gradient of the loss function with respect to the input tensor using the chain rule and the\n",
        "        # gradient of the loss function with respect to the output tensor\n",
        "        grad_wrt_input = torch.matmul(self.weights.t(), grad_wrt_out)\n",
        "        self.weights.grad = grad_wrt_weights\n",
        "        \n",
        "        return grad_wrt_input\n",
        "\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"\n",
        "        Update the weights and bias tensors using gradient descent.\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            self.weights -= self.lr * self.weights.grad\n",
        "            self.bias -= self.lr * self.bias.grad\n",
        "        \n",
        "    def zerograd(self):\n",
        "        \"\"\"\n",
        "        Reset the gradients of the weights and bias tensors to zero.\n",
        "        \"\"\"\n",
        "        if self.weights.grad is not None:\n",
        "            self.weights.grad.zero_()\n",
        "        if self.bias.grad is not None:\n",
        "            self.bias.grad.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a9c76d8-583d-4e1d-ad80-df194dbcec73",
      "metadata": {
        "id": "9a9c76d8-583d-4e1d-ad80-df194dbcec73"
      },
      "outputs": [],
      "source": [
        "class SoftmaxCrossEntropyLoss(object):\n",
        "    def __init__(self):\n",
        "        # Initialize the number of classes and batch size\n",
        "        self.num_classes, self.batch_size = None, None\n",
        "        \n",
        "        \n",
        "    def forward(self, logits, labels):\n",
        "        \"\"\"\n",
        "        logits are pre-softmax scores, labels are one-hot labels of given inputs\n",
        "        logits and labels are in the shape of (num_classes, batch_size)\n",
        "        returns loss as a scalar (i.e. mean value of the batch_size loss)\n",
        "        \"\"\"\n",
        "        # Save the logits and labels as class variables\n",
        "        self.logits = logits\n",
        "        self.labels = labels\n",
        "\n",
        "        # Get the batch size\n",
        "        self.batch_size = logits.shape[1]\n",
        "        \n",
        "        # Calculate softmax probabilities\n",
        "        logits_exp = torch.exp(logits)\n",
        "        self.probs = logits_exp / torch.sum(logits_exp, dim=0, keepdim=True)\n",
        "\n",
        "        # Calculate cross-entropy loss for each sample\n",
        "        log_probs = -torch.log(self.probs[labels.argmax(dim=1), range(self.batch_size)])\n",
        "        loss = torch.mean(log_probs)\n",
        "        \n",
        "        self.log_probs = log_probs\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def backward(self):\n",
        "        \"\"\"\n",
        "        return grad_wrt_logits shape (num_classes, batch_size)\n",
        "        (don't forget to divide by batch_size because your loss is a mean)\n",
        "        \"\"\"\n",
        "        # Create a copy of the probability tensor\n",
        "        grad_wrt_logits = self.probs.clone()\n",
        "\n",
        "        # Compute the gradient of the loss with respect to the logits\n",
        "        grad_wrt_logits[self.labels.argmax(dim=1), range(self.batch_size)] -= 1\n",
        "        grad_wrt_logits /= self.batch_size\n",
        "\n",
        "        # Return the gradient of the loss with respect to the logits\n",
        "        return grad_wrt_logits\n",
        "        \n",
        "    \n",
        "    def getAccu(self):\n",
        "        \"\"\"\n",
        "        return accuracy here\n",
        "        \"\"\"\n",
        "        # Compute the accuracy of the model\n",
        "        probs_labels = torch.argmax(self.probs, dim=0) == torch.argmax(self.labels, dim=1)\n",
        "        accuracy = probs_labels.sum().item() / self.labels.shape[0]\n",
        "        \n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d90dd004-812f-4c38-961f-559b2bee2e45",
      "metadata": {
        "id": "d90dd004-812f-4c38-961f-559b2bee2e45"
      },
      "outputs": [],
      "source": [
        "class SingleLayerMLP(Transform):\n",
        "    \"\"\"\n",
        "    Constructs a single layer neural network with the previous functions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, indim, outdim, hidden_layer=100, lr=0.001):\n",
        "        super(SingleLayerMLP, self).__init__()\n",
        "\n",
        "        # Create a LinearMap object for the first layer with input dimension indim, output dimension hidden_layer and learning rate lr.\n",
        "        self.linear_map = LinearMap(indim, hidden_layer, lr=lr)\n",
        "\n",
        "        # Create a ReLU activation function object.\n",
        "        self.relu = ReLU()\n",
        "\n",
        "        # Create a LinearMap object for the second layer with input dimension hidden_layer, output dimension hidden_layer and learning rate lr.\n",
        "        self.linear_map_2 = LinearMap(hidden_layer, hidden_layer, lr=lr)\n",
        "\n",
        "        # # Create a second ReLU activation function object.\n",
        "        # self.relu2 = ReLU()\n",
        "\n",
        "        # # Create a LinearMap object for the output layer with input dimension hidden_layer, output dimension outdim and learning rate lr.\n",
        "        # self.linear_map_3 = LinearMap(hidden_layer, outdim, lr=lr)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Performs forward pass for the single layer neural network.\n",
        "\n",
        "        x: Input tensor of shape (indim, batch_size)\n",
        "        out: Pre-softmax logits tensor of shape (outdim, batch_size)\n",
        "        \"\"\"\n",
        "        out = self.linear_map.forward(x)\n",
        "        out = self.relu.forward(out)\n",
        "        out = self.linear_map_2.forward(out)\n",
        "        # out = self.relu2.forward(out)\n",
        "        # out = self.linear_map_3.forward(out)\n",
        "        return out\n",
        "\n",
        "    def backward(self, grad_wrt_out):\n",
        "        \"\"\"\n",
        "        Performs backward pass for the single layer neural network.\n",
        "\n",
        "        Args:\n",
        "        grad_wrt_out: Gradient of the loss with respect to the output tensor, of shape (outdim, batch_size)\n",
        "\n",
        "        Returns:\n",
        "        grad_wrt_out: Gradient of the loss with respect to the input tensor, of shape (indim, batch_size)\n",
        "        \"\"\"\n",
        "        # grad_wrt_out = self.linear_map_3.backward(grad_wrt_out)\n",
        "        # grad_wrt_out = self.relu2.backward(grad_wrt_out)\n",
        "        grad_wrt_out = self.linear_map_2.backward(grad_wrt_out)\n",
        "        grad_wrt_out = self.relu.backward(grad_wrt_out)\n",
        "        grad_wrt_out = self.linear_map.backward(grad_wrt_out)\n",
        "        return grad_wrt_out\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"\n",
        "        Performs a gradient descent step on the model parameters for each layer.\n",
        "        \"\"\"\n",
        "        self.linear_map.step()\n",
        "        self.relu.step()\n",
        "        self.linear_map_2.step()\n",
        "        # self.relu2.step()\n",
        "        # self.linear_map_3.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1aba7a5-9607-4c22-b650-fcc5943f5207",
      "metadata": {
        "id": "f1aba7a5-9607-4c22-b650-fcc5943f5207"
      },
      "outputs": [],
      "source": [
        "class DS(Dataset):\n",
        "    \"\"\"\n",
        "    A PyTorch dataset class for loading data in batches.\n",
        "\n",
        "    X: Input tensor of shape (num_samples, num_features)\n",
        "    Y: Target tensor of shape (num_samples,)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, X: np.ndarray, Y: np.ndarray):\n",
        "        self.length = len(X)  # Total number of samples in the dataset\n",
        "        self.X = X  # Input tensor\n",
        "        self.Y = Y  # Target tensor\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns a single sample from the dataset.\n",
        "\n",
        "        idx: Index of the sample to retrieve\n",
        "\n",
        "        Returns:\n",
        "        A tuple containing the input tensor and target value for the sample at the given index\n",
        "        \"\"\"\n",
        "        x = self.X[idx, :]  # Get the input tensor for the given index\n",
        "        y = self.Y[idx]  # Get the target value for the given index\n",
        "        return (x, y)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the total number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return self.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7cc94fe-b5ee-48da-a4da-c37bfdbb9636",
      "metadata": {
        "id": "e7cc94fe-b5ee-48da-a4da-c37bfdbb9636"
      },
      "outputs": [],
      "source": [
        "# Function to train and test a model\n",
        "def train_test(train_loader, test_loader, model, num_epochs, loss_fn):\n",
        "    \n",
        "    # Initialize lists to store loss and accuracy values\n",
        "    training_loss = []\n",
        "    testing_loss = []\n",
        "    training_accuracy = []\n",
        "    test_accuracy = []\n",
        "    train_acc = []\n",
        "    \n",
        "    # Loop through epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        \n",
        "        # Loop through batches in training dataset\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.t().to(device)   # Transpose input and move to device (GPU or CPU)\n",
        "            target = target.t().to(device)   # Transpose labels and move to device\n",
        "            labels_onehot = torch.from_numpy(labels2onehot(target))   # Convert labels to one-hot encoding\n",
        "            \n",
        "            # Forward Pass \n",
        "            output = model.forward(data)   # Pass input through the model to get output\n",
        "            loss = loss_fn.forward(output, labels_onehot)   # Calculate loss using cross-entropy\n",
        "\n",
        "            # Backward Pass\n",
        "            grad = loss_fn.backward()   # Calculate gradients\n",
        "            model.backward(grad)   # Backpropagate the gradients through the model\n",
        "            model.step()   # Update the model parameters\n",
        "            \n",
        "            running_loss += loss.item()   # Add loss to running loss\n",
        "            train_acc.append(loss_fn.getAccu())   # Append accuracy to training accuracy list\n",
        "        \n",
        "        # Append average training loss and accuracy to lists\n",
        "        training_loss.append(running_loss / len(train_loader))\n",
        "        training_accuracy.append(np.mean(train_acc))\n",
        "        train_acc = []   # Reset training accuracy list\n",
        "        \n",
        "        # Evaluate model on test dataset\n",
        "        test_acc = []\n",
        "        test_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data = data.t().to(device)\n",
        "                target = target.t().to(device)\n",
        "                target = torch.from_numpy(labels2onehot(target))\n",
        "\n",
        "                # Forward Pass\n",
        "                output = model.forward(data)\n",
        "                loss = loss_fn.forward(output, target)\n",
        "\n",
        "                test_loss += loss.item()\n",
        "                test_acc.append(loss_fn.getAccu())\n",
        "        testing_loss.append(test_loss/len(test_loader))   # Append average test loss to list\n",
        "        test_accuracy.append(np.mean(test_acc))   # Append average test accuracy to list\n",
        "    \n",
        "    # Return loss and accuracy values for both training and testing\n",
        "    return training_loss, testing_loss, training_accuracy, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "103877a1-29ec-4d7e-a1e0-495572796c03",
      "metadata": {
        "id": "103877a1-29ec-4d7e-a1e0-495572796c03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c016a9-399b-4c47-ad61-d1c0c0f9bb05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500 10\n",
            "500 10\n"
          ]
        }
      ],
      "source": [
        "def labels2onehot(labels: np.ndarray):\n",
        "    return np.array([[i==lab for i in range(2)] for lab in labels]).astype(int)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"The dataset loaders were provided for you.\n",
        "    You need to implement your own training process.\n",
        "    You need plot the loss and accuracies during the training process and test process. \n",
        "    \"\"\"\n",
        "\n",
        "    indim = 10\n",
        "    outdim = 2\n",
        "    hidden_dim = 100\n",
        "    lr = 0.01\n",
        "    batch_size = 64\n",
        "    epochs = 200\n",
        "\n",
        "    #dataset\n",
        "    Xtrain = np.loadtxt(\"/content/XTrain.txt\", delimiter=\"\\t\")\n",
        "    Ytrain = np.loadtxt(\"/content/yTrain.txt\", delimiter=\"\\t\").astype(int)\n",
        "    m1, n1 = Xtrain.shape\n",
        "    print(m1, n1)\n",
        "    train_ds = DS(Xtrain, Ytrain)\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size)\n",
        "\n",
        "    Xtest = np.loadtxt(\"/content/XTest.txt\", delimiter=\"\\t\")\n",
        "    Ytest = np.loadtxt(\"/content/yTest.txt\", delimiter=\"\\t\").astype(int)\n",
        "    m2, n2 = Xtest.shape\n",
        "    print(m1, n2)\n",
        "    test_ds = DS(Xtest, Ytest)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
        "\n",
        "    #construct the model\n",
        "    model = SingleLayerMLP(indim, outdim, hidden_dim, lr)\n",
        "    # defining the loss function \n",
        "    loss_fn = SoftmaxCrossEntropyLoss()\n",
        "    \n",
        "    #construct the training and testing process\n",
        "    training_loss, testing_loss, training_acc, testing_acc = train_test(train_loader, test_loader, model, epochs, loss_fn)\n",
        "    # Train the model\n",
        "#     training_loss, training_acc = train(train_loader, model, epochs, loss_fn)\n",
        "\n",
        "#     # Test the trained model\n",
        "#     testing_loss, testing_acc = test(test_loader, model, epochs, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min(training_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuSd1FPy_4df",
        "outputId": "97ce6c80-e475-4a6f-fc75-f63a49feb8cd"
      },
      "id": "tuSd1FPy_4df",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1431847775174466"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(training_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r-wl9wS_8u7",
        "outputId": "3c3d936f-8346-46f9-dd75-a30e453196c9"
      },
      "id": "0r-wl9wS_8u7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.585063581905664"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be8d7039-0b32-47cb-acc3-899df0fc3c6a",
      "metadata": {
        "id": "be8d7039-0b32-47cb-acc3-899df0fc3c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "7689a3f5-2307-4b82-b359-2ef52aad83b2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"ff93a900-c4b9-4091-bda6-2ceca63af688\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff93a900-c4b9-4091-bda6-2ceca63af688\")) {                    Plotly.newPlot(                        \"ff93a900-c4b9-4091-bda6-2ceca63af688\",                        [{\"line\":{\"color\":\"green\"},\"name\":\"Training Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199],\"y\":[4.585063581905664,4.545226433415969,4.505445966890833,4.465715246636793,4.4260271897131,4.386374253272061,4.346748310359675,4.307140325917333,4.267539755829465,4.227934568654821,4.188311541649619,4.1486553682495675,4.108948219248526,4.06916976537703,4.029296389998112,3.989302283929889,3.9491560701645256,3.908822224323747,3.8682611832539457,3.8274277493942797,3.7862694369279115,3.7447243720540824,3.702726736731863,3.6602009511919547,3.6170596600462046,3.573204389376098,3.5285254563271993,3.4828982657523713,3.4361850009615824,3.3882323324675037,3.3388699174176404,3.2879127314721788,3.2351531890494734,3.1803705441005543,3.123328517854196,3.0637775083766594,3.0014657530183735,2.9361464601608036,2.867593296925749,2.7956211445918964,2.7201231580521394,2.641099804029151,2.558718394890356,2.4733526263419217,2.385650082250139,2.296565690830911,2.207341516208384,2.11943704825518,2.0343812832069204,1.9535786357843992,1.8781173539074179,1.8086567059604195,1.7453992376809297,1.6881634239570416,1.6364987244812688,1.5898019907558274,1.5474171162773258,1.5087024813804282,1.4730699476712568,1.4400002173426745,1.4090457953780307,1.379826501639812,1.3520233222997606,1.3253692601863916,1.299636547265012,1.274634165482813,1.2502003426902906,1.2261929588253788,1.202489849849545,1.1789811058502817,1.1555670988370532,1.132159980046437,1.1086813077409796,1.0850532081515962,1.0612089579354151,1.0370848440370521,1.0126242909542154,0.9877765082472714,0.9624953970317951,0.9367508156679861,0.9105264523008095,0.8838169194288523,0.8566322693994758,0.8290059862138814,0.8009980497089622,0.772686171122044,0.7441781490112713,0.7156112588725037,0.687137614123612,0.6589268922218314,0.6311558573897295,0.6040047025256987,0.5776448856846116,0.5522283670212736,0.5278820389213731,0.5047039018120408,0.482760929887814,0.46208546383671456,0.44268574271882377,0.4245471837612885,0.4076338669843489,0.3918960594524174,0.37727485739815125,0.3637034517347825,0.3511127126426394,0.3394324447652273,0.32859450763609027,0.3185336399694198,0.3091872029600141,0.3004981319494942,0.2924118895699313,0.2848740103861727,0.2778383030362649,0.2712658972540124,0.26511863970154925,0.2593624149506071,0.2539658804634835,0.24889961761721296,0.24413643095240853,0.23965145126563475,0.23542295921777442,0.2314329221815328,0.22766382690492049,0.2240987919605713,0.22072465720542642,0.21752704344154478,0.21449271445386686,0.21161045513252444,0.20887080206853226,0.20626352397521983,0.20377979763697412,0.20141290257047648,0.19915495888156318,0.19699837774650977,0.19493670588557563,0.1929665414724721,0.19108190993017005,0.18927612888256562,0.18754474966901638,0.18588388329389816,0.18428984485213354,0.182759447465573,0.18128894300743123,0.17987484212122623,0.1785141475664108,0.1772043891320569,0.17594278152375115,0.1747265928764357,0.17355360085359509,0.17242136577489792,0.17132802062923375,0.17027170953435866,0.16925059669238687,0.16826305705795983,0.16730755443450446,0.16638266747799751,0.1654871114407789,0.16461941629164611,0.16377835837236754,0.1629627906699364,0.16217162328202575,0.16140396550572866,0.16065891280042024,0.15993569966860416,0.1592332774815494,0.15855060626455045,0.15788697491160628,0.15724176143970453,0.1566145140861482,0.1560042920365288,0.15541026136380465,0.15483178815480414,0.1542684260356768,0.15371954442612298,0.15318464160842327,0.15266316303189395,0.15215467881902137,0.1516586382592829,0.15117459871404482,0.15070214224293815,0.15024093525615936,0.14979079227096553,0.14935098677330247,0.1489212522835165,0.1485012536747456,0.14809066939141072,0.14768919477520395,0.14729655225348376,0.146912475471192,0.1465367668411183,0.14616910995497176,0.14580953904494864,0.14545726642509466,0.14511245805008038,0.144774884163176,0.1444437906854692,0.1441196354138744,0.14380184661368056,0.1434902877644831,0.1431847775174466],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"name\":\"Test Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199],\"y\":[4.562713998111619,4.522928940695688,4.483197231263732,4.443512184076902,4.4038668572935356,4.364253811356026,4.32466494485695,4.285090461489196,4.2455198178665885,4.205939700034472,4.166337285888974,4.126696512589843,4.086999413808637,4.047222512654053,4.007341948376743,3.9673261773220654,3.9271422699678427,3.8867523824333716,3.8461150755852094,3.8051835181521922,3.7638980769778816,3.7221933177649134,3.679999459823219,3.6372382687320206,3.5938133006110506,3.5496198997494006,3.504541901539314,3.458449953476669,3.4111929481949828,3.3626106873079906,3.3125208875994274,3.2607266015241203,3.2070114083018204,3.151139440912668,3.092862193966523,3.0319233680132855,2.968067539035678,2.9010428570336773,2.830624098903929,2.756641254788855,2.6790079202560415,2.5977699118080846,2.5131416146270835,2.425571336171122,2.3357966833693444,2.2448620757851225,2.1540889872548736,2.064981249288701,1.9790707562234098,1.8977102121969536,1.8219126999892519,1.7522494191898543,1.6888568552867098,1.631511642477075,1.5797443750243723,1.5329527197698471,1.4904899702645373,1.4517277763406096,1.416087024842221,1.3830545274971195,1.3521844440105428,1.3230960776963223,1.295466907207429,1.2690229081190851,1.2435292775589304,1.218788560315267,1.1946298726879094,1.170903777740364,1.1474802773662567,1.1242400285623921,1.1010765007304744,1.0778956792784022,1.0546121189425834,1.0311432715421345,1.0074185197928547,0.9833686456956915,0.9589356927860929,0.934073427110645,0.9087349920985698,0.8828995172038474,0.8565580373393238,0.8297142635678465,0.8024065738145896,0.7746897280755648,0.7466459345185897,0.7183873524422036,0.6900621951409179,0.6618347870528292,0.6338851343265401,0.6064086383312782,0.5796012282244345,0.5536548715883918,0.52873497363337,0.5049844722229517,0.4825086982350774,0.46137498570944646,0.4416168600847167,0.42323154564787635,0.4061896390442217,0.3904440244500972,0.3759311441350202,0.3625780718880981,0.35030287217762923,0.33902482273245055,0.3286619036964665,0.3191357797873473,0.3103721767489691,0.3023021596792003,0.2948624452764228,0.2879960652253012,0.281649369696064,0.2757718494294119,0.2703241691097428,0.26526606574916,0.2605623470837727,0.2561812460077774,0.252094559267119,0.24827699001855807,0.24470564816167079,0.24136486050597472,0.23823082187950162,0.23528665749518912,0.23253025907166708,0.22993675145477832,0.22749148239394704,0.22518364307139357,0.22300442573028703,0.2209441151664328,0.2189928288401063,0.2171438236915461,0.21538942211743245,0.21372278030930378,0.21213840972412037,0.21063145668435246,0.2091969020785094,0.2078338025860706,0.20653373103715744,0.20529331426039096,0.20410883085725,0.20297709705399386,0.20189532139437377,0.20086040820313217,0.19987070712362073,0.1989221645419595,0.19801262130968944,0.19713920168570748,0.1963010207452552,0.19549490717776669,0.19472060112854972,0.19397626923167668,0.19325949601199593,0.19257056762328492,0.19190731518552295,0.1912684294731874,0.19065280489619016,0.19005985414538498,0.1894883117802737,0.18893697759014308,0.18840495529766807,0.1878912292462939,0.18739498917477526,0.1869151039127676,0.18645078494280476,0.18600097349288086,0.18556574839838313,0.18514448754855445,0.18473642121484013,0.18434052743821172,0.1839560071807154,0.1835830176931383,0.18322142096098382,0.18287065674805358,0.18253035820017188,0.18220005168530917,0.18187903979559628,0.18156761060879895,0.18126507206183223,0.1809710689580707,0.18068527783356203,0.18040743249861707,0.18013695757005,0.17987247057487418,0.17961505597567715,0.17936451118482968,0.17912053893738844,0.17888289514091146,0.17865101361731564,0.1784244446876466,0.17820245803573578,0.17798638835200387,0.17777553546833294,0.17756844047149323,0.17736538276545194,0.17716713185353167,0.17697366795949443,0.1767844473601965,0.17659862264023096,0.17641698004091122,0.17623939762037927,0.17606575285228454],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"annotations\":[{\"arrowhead\":1,\"ax\":-50,\"ay\":-50,\"showarrow\":true,\"text\":\"Min Training Loss: 0.14\",\"x\":199,\"y\":0.1431847775174466},{\"arrowhead\":1,\"ax\":-50,\"ay\":50,\"showarrow\":true,\"text\":\"Min Test Loss: 0.18\",\"x\":199,\"y\":0.17606575285228454}],\"title\":{\"text\":\"Training vs. Test Losses for Scratch NN Implementation\"},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ff93a900-c4b9-4091-bda6-2ceca63af688');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "# Add training and test loss traces to the figure\n",
        "fig.add_trace(go.Scatter(x=list(range(len(training_loss))), y=training_loss, name='Training Loss', line=dict(color='green')))\n",
        "fig.add_trace(go.Scatter(x=list(range(len(testing_loss))), y=testing_loss, name='Test Loss', line=dict(color='red')))\n",
        "\n",
        "# Add markers at the minimum values of the training and test losses\n",
        "train_min_index = training_loss.index(min(training_loss))\n",
        "test_min_index = testing_loss.index(min(testing_loss))\n",
        "\n",
        "fig.add_annotation(x=train_min_index, y=training_loss[train_min_index], text=f\"Min Training Loss: {round(training_loss[train_min_index], 2)}\", showarrow=True, arrowhead=1, ax=-50, ay=-50)\n",
        "fig.add_annotation(x=test_min_index, y=testing_loss[test_min_index], text=f\"Min Test Loss: {round(testing_loss[test_min_index], 2)}\", showarrow=True, arrowhead=1, ax=-50, ay=50)\n",
        "\n",
        "fig.update_layout(title='Training vs. Test Losses for Scratch NN Implementation', xaxis_title='Epochs', yaxis_title='Loss', height=600, width= 800)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OjfE0Tdz_7tS"
      },
      "id": "OjfE0Tdz_7tS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d8ee089-e2ca-4223-a64b-b3b33a76e52d",
      "metadata": {
        "id": "2d8ee089-e2ca-4223-a64b-b3b33a76e52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "7e5e309f-4e74-460b-ee5d-1f8307520dc1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"836f0a6d-dd99-4694-af1a-e95d1f31e4da\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"836f0a6d-dd99-4694-af1a-e95d1f31e4da\")) {                    Plotly.newPlot(                        \"836f0a6d-dd99-4694-af1a-e95d1f31e4da\",                        [{\"line\":{\"color\":\"green\"},\"name\":\"Training Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199],\"y\":[0.4522235576923077,0.5673076923076923,0.6457331730769231,0.7134915865384616,0.744140625,0.775390625,0.7797475961538461,0.7919170673076923,0.7817007211538461,0.78515625,0.779296875,0.7958233173076923,0.7914663461538461,0.7890625,0.78515625,0.783203125,0.7768930288461539,0.775390625,0.7690805288461539,0.763671875,0.7534555288461539,0.7456430288461539,0.7412860576923077,0.7310697115384616,0.7252103365384616,0.7173978365384616,0.7173978365384616,0.7154447115384616,0.7193509615384616,0.7291165865384616,0.7310697115384616,0.7330228365384616,0.7447415865384616,0.7534555288461539,0.76171875,0.765625,0.7734375,0.7817007211538461,0.7938701923076923,0.7997295673076923,0.8036358173076923,0.8036358173076923,0.8192608173076923,0.8231670673076923,0.8255709134615384,0.8255709134615384,0.8255709134615384,0.8294771634615384,0.8338341346153846,0.8416466346153846,0.8475060096153846,0.8475060096153846,0.8475060096153846,0.8494591346153846,0.8518629807692308,0.8518629807692308,0.8518629807692308,0.8518629807692308,0.8557692307692308,0.8616286057692308,0.8635817307692308,0.8674879807692308,0.8694411057692308,0.8733473557692308,0.8772536057692308,0.8792067307692308,0.8811598557692308,0.8831129807692308,0.8889723557692308,0.8889723557692308,0.8909254807692308,0.8909254807692308,0.8928786057692308,0.8948317307692308,0.8991887019230769,0.9011418269230769,0.9011418269230769,0.9011418269230769,0.9054987980769231,0.9118088942307692,0.9157151442307692,0.9176682692307692,0.9176682692307692,0.9196213942307692,0.9215745192307692,0.9215745192307692,0.9215745192307692,0.9254807692307692,0.9298377403846154,0.9337439903846154,0.9396033653846154,0.9396033653846154,0.9415564903846154,0.9415564903846154,0.9439603365384616,0.9439603365384616,0.9459134615384616,0.9439603365384616,0.9478665865384616,0.9478665865384616,0.9478665865384616,0.9478665865384616,0.9478665865384616,0.9498197115384616,0.9498197115384616,0.9517728365384616,0.9537259615384616,0.9537259615384616,0.9556790865384616,0.9556790865384616,0.9595853365384616,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9591346153846154,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9615384615384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616,0.9634915865384616],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\"},\"name\":\"Test Loss\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199],\"y\":[0.48828125,0.5859375,0.703125,0.76953125,0.78515625,0.78125,0.77734375,0.796875,0.796875,0.80859375,0.8125,0.81640625,0.82421875,0.828125,0.82421875,0.82421875,0.8203125,0.82421875,0.8203125,0.81640625,0.8203125,0.8203125,0.8203125,0.8203125,0.8203125,0.8203125,0.8203125,0.82421875,0.82421875,0.82421875,0.83203125,0.83203125,0.83203125,0.83984375,0.84375,0.84765625,0.84765625,0.8515625,0.85546875,0.859375,0.859375,0.859375,0.859375,0.859375,0.87109375,0.8828125,0.8828125,0.88671875,0.88671875,0.88671875,0.88671875,0.88671875,0.88671875,0.890625,0.890625,0.890625,0.890625,0.890625,0.890625,0.890625,0.890625,0.890625,0.890625,0.890625,0.89453125,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.90234375,0.91015625,0.91015625,0.9140625,0.9140625,0.9140625,0.9140625,0.9140625,0.9140625,0.91796875,0.921875,0.921875,0.91796875,0.91796875,0.921875,0.921875,0.921875,0.921875,0.921875,0.921875,0.921875,0.921875,0.921875,0.91796875,0.91796875,0.91796875,0.91796875,0.921875,0.921875,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125,0.953125],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"annotations\":[{\"arrowhead\":1,\"ax\":-50,\"ay\":-50,\"showarrow\":true,\"text\":\"Max Training Accuracy: 0.96\",\"x\":199,\"y\":0.9634915865384616},{\"arrowhead\":1,\"ax\":-50,\"ay\":50,\"showarrow\":true,\"text\":\"Max Test Accuracy: 0.95\",\"x\":199,\"y\":0.953125}],\"title\":{\"text\":\"Training vs. Test Accuracies for Scratch NN Implementation\"},\"xaxis\":{\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('836f0a6d-dd99-4694-af1a-e95d1f31e4da');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "# Add training and test loss traces to the figure\n",
        "fig.add_trace(go.Scatter(x=list(range(len(training_acc))), y=training_acc, name='Training Loss', line=dict(color='green')))\n",
        "fig.add_trace(go.Scatter(x=list(range(len(testing_acc))), y=testing_acc, name='Test Loss', line=dict(color='red')))\n",
        "\n",
        "# Add markers at the minimum values of the training and test losses\n",
        "train_min_index = len(training_acc)-1\n",
        "test_min_index = len(testing_acc)-1\n",
        "\n",
        "fig.add_annotation(x=len(training_acc)-1, y=training_acc[-1], text=f\"Max Training Accuracy: {round(training_acc[-1], 2)}\", showarrow=True, arrowhead=1, ax=-50, ay=-50)\n",
        "fig.add_annotation(x=test_min_index, y=testing_acc[-1], text=f\"Max Test Accuracy: {round(testing_acc[-1], 2)}\", showarrow=True, arrowhead=1, ax=-50, ay=50)\n",
        "\n",
        "fig.update_layout(title='Training vs. Test Accuracies for Scratch NN Implementation', xaxis_title='Epochs', yaxis_title='Loss', height=600, width= 800)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89fe99a3-6114-4939-a3ff-5eb643d455ae",
      "metadata": {
        "id": "89fe99a3-6114-4939-a3ff-5eb643d455ae"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}